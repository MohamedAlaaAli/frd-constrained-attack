{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54eb733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 19:31:16.901630: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 19:31:17.388001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-26 19:31:18.733359: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Builtin\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Third Party\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Attacks\n",
    "from attacks.fgsm import fgsm_l2_attack, fgsm_l2_attack_dct\n",
    "from attacks.pgd import pgd_l2_attack, pgd_l2_attack_dct\n",
    "from attacks.simba import simba_attack\n",
    "from attacks.one_pixel import one_pixel_attack\n",
    "\n",
    "# Models\n",
    "from models.clip import CLIPImageEmbedder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3152d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000PILDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, save_dir, ids, extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.extensions = extensions\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname)\n",
    "            for root, _, files in os.walk(root_dir)\n",
    "            for fname in files\n",
    "            if fname.lower().endswith(extensions) and fname.startswith(ids)\n",
    "        ]\n",
    "\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in {root_dir} with extensions {extensions}\")\n",
    "        \n",
    "        for idx, path in enumerate(self.image_paths):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = img.resize((224, 224), Image.BILINEAR)\n",
    "            \n",
    "            new_path = os.path.join(save_dir, os.path.basename(path))\n",
    "            self.image_paths[idx] = new_path\n",
    "\n",
    "            img.save(new_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = torch.from_numpy(np.array(img)).permute(2, 0, 1).float()/255.0\n",
    "        return (img, self.image_paths[idx])\n",
    "\n",
    "def get_image_dataloader_ham(root_dir, save_dir, ids, batch_size=8, num_workers=4, shuffle=False):\n",
    "\n",
    "    assert Path(root_dir).is_dir()\n",
    "    assert Path(save_dir).is_dir()\n",
    "    \n",
    "    dataset = HAM10000PILDataset(root_dir, save_dir, ids)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1900fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMFPILDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, save_dir, ids, extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.extensions = extensions\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname)\n",
    "            for root, _, files in os.walk(root_dir)\n",
    "            for fname in files\n",
    "            if fname.lower().endswith(extensions) and (fname.split(\".\")[0] in ids)\n",
    "        ]\n",
    "\n",
    "    \n",
    "        print(len(self.image_paths))\n",
    "\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in {root_dir} with extensions {extensions}\")\n",
    "        \n",
    "        for idx, path in enumerate(self.image_paths):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = img.resize((224, 224), Image.BILINEAR)\n",
    "            \n",
    "            new_path = os.path.join(save_dir, os.path.basename(path))\n",
    "            self.image_paths[idx] = new_path\n",
    "\n",
    "            img.save(new_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = torch.from_numpy(np.array(img)).permute(2, 0, 1).float()/255.0\n",
    "        return (img, self.image_paths[idx])\n",
    "\n",
    "def get_image_dataloader_dmf(root_dir, save_dir, ids, batch_size=8, num_workers=4, shuffle=False):\n",
    "\n",
    "    assert Path(root_dir).is_dir()\n",
    "    assert Path(save_dir).is_dir()\n",
    "    \n",
    "    dataset = DMFPILDataset(root_dir, save_dir, ids)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DERM7PTPILDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, save_dir, test_ids, meta, extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.extensions = extensions\n",
    "        self.image_paths = [\n",
    "            os.path.join(os.path.join(root_dir, \"images\"), meta.iloc[case_num]['derm']) \n",
    "            for case_num in test_ids['image_id']\n",
    "        ]\n",
    "\n",
    "\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in {root_dir} with extensions {extensions}\")\n",
    "        \n",
    "        for idx, path in enumerate(self.image_paths):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = img.resize((224, 224), Image.BILINEAR)\n",
    "            \n",
    "            new_path = os.path.join(save_dir, os.path.basename(path))\n",
    "            self.image_paths[idx] = new_path\n",
    "\n",
    "            img.save(new_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = torch.from_numpy(np.array(img)).permute(2, 0, 1).float()/255.0\n",
    "        return (img, self.image_paths[idx])\n",
    "\n",
    "def get_image_dataloader_d7p(root_dir, save_dir, ids, meta, batch_size=8, num_workers=4, shuffle=False):\n",
    "\n",
    "    assert Path(root_dir).is_dir()\n",
    "    assert Path(save_dir).is_dir()\n",
    "    \n",
    "    dataset = DERM7PTPILDataset(root_dir, save_dir, ids, meta)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c4c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adv_batch(batch, save_dir=\"datasets/adv_simba/busi\", pth=None):\n",
    "    \"\"\"\n",
    "    Save each tensor in the batch as a .bmp image, keeping numbering across calls.\n",
    "    Assumes images are in [0,1] range (float) or [0,255] (uint8).\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for img, p in zip(batch, pth):\n",
    "        img = img.detach().cpu()\n",
    "\n",
    "        # Remove batch dimension if present: [1, C, H, W] -> [C, H, W]\n",
    "        if img.dim() == 4:\n",
    "            img = img.squeeze(0)\n",
    "\n",
    "        # If image is [C, H, W], convert to [H, W, C]\n",
    "        if img.dim() == 3:\n",
    "            img = img.permute(1, 2, 0)\n",
    "        \n",
    "        # Scale to 0â€“255 and convert to uint8 if needed\n",
    "        if img.dtype != torch.uint8:\n",
    "            img = (img * 255).clamp(0, 255).byte()\n",
    "\n",
    "        img_pil = Image.fromarray(img.numpy())\n",
    "        file_path = os.path.join(save_dir, os.path.basename(p))\n",
    "        img_pil.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9426add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "TEST_IDS_PATH = \"test_sets/test_ids\"\n",
    "TEST_IMAGES_PATH = \"test_sets/test_images\"\n",
    "\n",
    "HAM_DATASET = \"datasets/HAM\"\n",
    "DERM7PT_DATASET = \"datasets/DERM7PT\"\n",
    "DMF_DATASET = \"datasets/DMF\"\n",
    "\n",
    "EPSILON = 0.05\n",
    "TEMPERATURE = 0.5\n",
    "\n",
    "FGSM_L2 = \"results/{dataset}/FGSM\"\n",
    "FGSM_DCT_L2 = \"results/{dataset}/FGSM_DCT\"\n",
    "FGSM_L2_TEST = \"results/{dataset}/FGSM_TEST\"\n",
    "\n",
    "PGD_L2 = \"results/{dataset}/PGD\"\n",
    "PGD_DCT_L2 = \"results/{dataset}/PGD_DCT\"\n",
    "\n",
    "ONE_PIXEL_L2 = \"results/{dataset}/ONE_PIXEL\"\n",
    "SIMBA_L2 = \"results/{dataset}/SIMBA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3613b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "model = CLIPImageEmbedder(device= 'cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6bb76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "# HAM Dataset\n",
    "ham_test_ids = pd.read_csv(os.path.join(TEST_IDS_PATH, \"ham_ids.csv\"))\n",
    "ham_test_ids = tuple(list(element.item() for element in ham_test_ids.to_numpy()))\n",
    "ham_loader = get_image_dataloader_ham(HAM_DATASET, os.path.join(TEST_IMAGES_PATH, \"ham\"), ham_test_ids, batch_size=1)\n",
    "\n",
    "\n",
    "# DERM7PT Dataset\n",
    "derm7pt_ids = pd.read_csv(os.path.join(TEST_IDS_PATH, \"d7p_ids.csv\"))\n",
    "derm7pt_meta = pd.read_csv(os.path.join(DERM7PT_DATASET, \"meta/meta.csv\"))\n",
    "derm7pt_loader = get_image_dataloader_d7p(DERM7PT_DATASET, os.path.join(TEST_IMAGES_PATH, \"derm7pt\"), ids=derm7pt_ids, meta=derm7pt_meta, batch_size=1)\n",
    "\n",
    "# DMF Dataset\n",
    "dmf_test_ids = pd.read_csv(os.path.join(TEST_IDS_PATH, \"dmf_ids.csv\"))\n",
    "dmf_test_ids = tuple(list(element.item() for element in dmf_test_ids.to_numpy()))\n",
    "dmf_loader = get_image_dataloader_dmf(DMF_DATASET, os.path.join(TEST_IMAGES_PATH, \"dmf\"), ids=dmf_test_ids, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a08213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmf_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b51dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in derm7pt_loader:\n",
    "\n",
    "    pass\n",
    "\n",
    "    # result, pth = simba_attack(batch, model, epsilon=EPSILON, step_size=EPSILON)\n",
    "    # save_adv_batch(result, SIMBA_L2.format(dataset=\"derm7pt\"), pth=pth)\n",
    "\n",
    "    # result, pth = pgd_l2_attack(model, batch, EPSILON, EPSILON/4, 200)\n",
    "    # save_adv_batch(result, PGD_L2.format(dataset=\"derm7pt\"), pth=pth)\n",
    "\n",
    "    # result, pth = pgd_l2_attack_dct(model, batch, EPSILON, EPSILON/4, 200)\n",
    "    # save_adv_batch(result, PGD_DCT_L2.format(dataset=\"derm7pt\"), pth=pth)\n",
    "\n",
    "    # result, pth = fgsm_l2_attack(model, x=batch, epsilon=EPSILON)\n",
    "    # save_adv_batch(result, FGSM_L2.format(dataset=\"derm7pt\"), pth=pth)\n",
    "\n",
    "    # result, pth = fgsm_l2_attack_dct(model, x=batch, epsilon=EPSILON)\n",
    "    # save_adv_batch(result, FGSM_DCT_L2.format(dataset=\"derm7pt\"), pth=pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n"
     ]
    }
   ],
   "source": [
    "for batch in dmf_loader:\n",
    "\n",
    "\n",
    "    batch_exist = False\n",
    "\n",
    "    for pth in batch[1]:\n",
    "        new_path = os.path.join((SIMBA_L2).format(dataset=\"dmf\"), os.path.basename(pth))\n",
    "        if os.path.exists(new_path):\n",
    "            batch_exist = True\n",
    "\n",
    "    if batch_exist:\n",
    "        print(\"skipped\")\n",
    "        continue\n",
    "\n",
    "    # result, pth = simba_attack(batch, model, epsilon=EPSILON, step_size=EPSILON)\n",
    "    # save_adv_batch(result, SIMBA_L2.format(dataset=\"dmf\"), pth=pth)\n",
    "\n",
    "    # result, pth = pgd_l2_attack(model, batch, EPSILON, EPSILON/4, 200)\n",
    "    # save_adv_batch(result, PGD_L2.format(dataset=\"dmf\"), pth=pth)\n",
    "\n",
    "    # result, pth = pgd_l2_attack_dct(model, batch, EPSILON, EPSILON/4, 200)\n",
    "    # save_adv_batch(result, PGD_DCT_L2.format(dataset=\"dmf\"), pth=pth)\n",
    "\n",
    "    # result, pth = fgsm_l2_attack(model, x=batch, epsilon=EPSILON)\n",
    "    # save_adv_batch(result, FGSM_L2.format(dataset=\"dmf\"), pth=pth)\n",
    "\n",
    "    # result, pth = fgsm_l2_attack_dct(model, x=batch, epsilon=EPSILON)\n",
    "    # save_adv_batch(result, FGSM_DCT_L2.format(dataset=\"dmf\"), pth=pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n"
     ]
    }
   ],
   "source": [
    "for batch in ham_loader:\n",
    "\n",
    "    batch_exist = False\n",
    "\n",
    "    for pth in batch[1]:\n",
    "        new_path = os.path.join((SIMBA_L2).format(dataset=\"ham\"), os.path.basename(pth))\n",
    "        if os.path.exists(new_path):\n",
    "            batch_exist = True\n",
    "\n",
    "    if batch_exist:\n",
    "        print(\"skipped\")\n",
    "        continue\n",
    "\n",
    "    result, pth = simba_attack(batch, model, epsilon=EPSILON, step_size=EPSILON)\n",
    "    save_adv_batch(result, SIMBA_L2.format(dataset=\"ham\"), pth=pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abeb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab359aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee3247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09260b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
